{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Market Analyzer - Analysis Demo\n",
    "\n",
    "This notebook demonstrates interactive analysis and visualization of job market data.\n",
    "\n",
    "**Prerequisites:** Run the full pipeline first (`make run` or `run_all.sh`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed job data\n",
    "jobs_df = pd.read_csv('../data/jobs_with_skills.csv')\n",
    "\n",
    "print(f\"Loaded {len(jobs_df)} job postings\")\n",
    "print(f\"Columns: {jobs_df.columns.tolist()[:10]}...\")\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Skill Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skills per job distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(jobs_df['num_skills'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Skills per Job')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Skills per Job Posting')\n",
    "plt.axvline(jobs_df['num_skills'].mean(), color='red', linestyle='--', label=f\"Mean: {jobs_df['num_skills'].mean():.1f}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average skills per job: {jobs_df['num_skills'].mean():.2f}\")\n",
    "print(f\"Median skills per job: {jobs_df['num_skills'].median():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 most demanded skills\n",
    "skill_counts = {}\n",
    "for skills_str in jobs_df['extracted_skills']:\n",
    "    if pd.notna(skills_str) and skills_str:\n",
    "        skills = [s.strip() for s in str(skills_str).split(';') if s.strip()]\n",
    "        for skill in skills:\n",
    "            skill_counts[skill] = skill_counts.get(skill, 0) + 1\n",
    "\n",
    "top_skills = pd.DataFrame(list(skill_counts.items()), columns=['Skill', 'Count']).sort_values('Count', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_skills['Skill'], top_skills['Count'], color='steelblue')\n",
    "plt.xlabel('Number of Job Postings')\n",
    "plt.title('Top 20 Most Demanded Skills')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Skills:\")\n",
    "print(top_skills.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs by location\n",
    "location_counts = jobs_df['location_normalized'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "location_counts.plot(kind='bar', color='coral')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Number of Jobs')\n",
    "plt.title('Top 10 Cities by Job Postings')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Cities:\")\n",
    "print(location_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jobs by tier and region\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "if 'city_tier' in jobs_df.columns:\n",
    "    tier_counts = jobs_df['city_tier'].value_counts()\n",
    "    axes[0].pie(tier_counts.values, labels=tier_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0].set_title('Jobs by City Tier')\n",
    "\n",
    "if 'region' in jobs_df.columns:\n",
    "    region_counts = jobs_df['region'].value_counts()\n",
    "    axes[1].pie(region_counts.values, labels=region_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Jobs by Region')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skill Co-occurrence Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network graph (if available)\n",
    "network_path = Path('../exports/skill_network.graphml')\n",
    "\n",
    "if network_path.exists():\n",
    "    G = nx.read_graphml(network_path)\n",
    "    \n",
    "    # Get top nodes by degree\n",
    "    degrees = dict(G.degree())\n",
    "    top_nodes = sorted(degrees, key=degrees.get, reverse=True)[:15]\n",
    "    subgraph = G.subgraph(top_nodes)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = nx.spring_layout(subgraph, k=2, iterations=50)\n",
    "    \n",
    "    # Node sizes based on degree\n",
    "    node_sizes = [degrees[node] * 100 for node in subgraph.nodes()]\n",
    "    \n",
    "    nx.draw_networkx_nodes(subgraph, pos, node_size=node_sizes, node_color='lightblue', alpha=0.7)\n",
    "    nx.draw_networkx_edges(subgraph, pos, alpha=0.3, width=2)\n",
    "    nx.draw_networkx_labels(subgraph, pos, font_size=10, font_weight='bold')\n",
    "    \n",
    "    plt.title('Skill Co-occurrence Network (Top 15 Skills)', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Network has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "else:\n",
    "    print(\"Network file not found. Run skill_cooccurrence.py first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trend data\n",
    "trends_path = Path('../exports/trends.csv')\n",
    "\n",
    "if trends_path.exists():\n",
    "    trends_df = pd.read_csv(trends_path)\n",
    "    \n",
    "    # Get top 5 skills by total mentions\n",
    "    skill_totals = trends_df.groupby('skill')['count'].sum().sort_values(ascending=False).head(5)\n",
    "    top_5_skills = skill_totals.index.tolist()\n",
    "    \n",
    "    # Plot trends\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    for skill in top_5_skills:\n",
    "        skill_data = trends_df[trends_df['skill'] == skill].sort_values('period')\n",
    "        plt.plot(skill_data['period'], skill_data['count'], marker='o', label=skill, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Mentions')\n",
    "    plt.title('Top 5 Skills Trend Over Time')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Trends file not found. Run trend_analysis.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load growth metrics\n",
    "growth_path = Path('../exports/trends_growth.csv')\n",
    "\n",
    "if growth_path.exists():\n",
    "    growth_df = pd.read_csv(growth_path)\n",
    "    \n",
    "    # Emerging skills\n",
    "    emerging = growth_df[growth_df['growth_rate'] > 0].head(10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(emerging['skill'], emerging['growth_rate'] * 100, color='green', alpha=0.7)\n",
    "    plt.xlabel('Growth Rate (%)')\n",
    "    plt.title('Top 10 Emerging Skills (Highest Growth)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop Emerging Skills:\")\n",
    "    print(emerging[['skill', 'growth_rate', 'total_mentions']].head())\n",
    "else:\n",
    "    print(\"Growth metrics not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Salary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary distribution\n",
    "if 'salary_min' in jobs_df.columns and 'salary_max' in jobs_df.columns:\n",
    "    valid_salaries = jobs_df[(jobs_df['salary_min'].notna()) & (jobs_df['salary_max'].notna())]\n",
    "    \n",
    "    if len(valid_salaries) > 0:\n",
    "        valid_salaries['avg_salary'] = (valid_salaries['salary_min'] + valid_salaries['salary_max']) / 2\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Histogram\n",
    "        axes[0].hist(valid_salaries['avg_salary'] / 100000, bins=20, edgecolor='black', alpha=0.7)\n",
    "        axes[0].set_xlabel('Average Salary (Lakhs)')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].set_title('Salary Distribution')\n",
    "        \n",
    "        # Box plot by location\n",
    "        top_locations = valid_salaries['location_normalized'].value_counts().head(5).index\n",
    "        location_salary_data = [valid_salaries[valid_salaries['location_normalized'] == loc]['avg_salary'] / 100000 \n",
    "                               for loc in top_locations]\n",
    "        \n",
    "        axes[1].boxplot(location_salary_data, labels=top_locations)\n",
    "        axes[1].set_ylabel('Average Salary (Lakhs)')\n",
    "        axes[1].set_title('Salary by Top 5 Cities')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nMedian Salary: ₹{valid_salaries['avg_salary'].median() / 100000:.2f} Lakhs\")\n",
    "        print(f\"Mean Salary: ₹{valid_salaries['avg_salary'].mean() / 100000:.2f} Lakhs\")\n",
    "else:\n",
    "    print(\"Salary data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experience Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience distribution\n",
    "if 'experience_years' in jobs_df.columns:\n",
    "    valid_exp = jobs_df[jobs_df['experience_years'].notna()]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(valid_exp['experience_years'], bins=range(0, 11), edgecolor='black', alpha=0.7, color='purple')\n",
    "    plt.xlabel('Years of Experience Required')\n",
    "    plt.ylabel('Number of Jobs')\n",
    "    plt.title('Distribution of Experience Requirements')\n",
    "    plt.xticks(range(0, 11))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nMedian Experience: {valid_exp['experience_years'].median():.0f} years\")\n",
    "    print(f\"Mean Experience: {valid_exp['experience_years'].mean():.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"JOB MARKET ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal Job Postings: {len(jobs_df)}\")\n",
    "print(f\"Unique Skills: {len(skill_counts)}\")\n",
    "print(f\"Unique Locations: {jobs_df['location_normalized'].nunique()}\")\n",
    "print(f\"Date Range: {jobs_df['posted_date'].min()} to {jobs_df['posted_date'].max()}\")\n",
    "\n",
    "if 'title_normalized' in jobs_df.columns:\n",
    "    print(f\"\\nTop 5 Job Titles:\")\n",
    "    for title, count in jobs_df['title_normalized'].value_counts().head(5).items():\n",
    "        print(f\"  {title}: {count}\")\n",
    "\n",
    "print(\"\\nTop 5 Skills:\")\n",
    "for idx, row in top_skills.head(5).iterrows():\n",
    "    print(f\"  {row['Skill']}: {row['Count']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Tableau**: Import CSV files from `exports/tableau_ready/` for interactive dashboards\n",
    "2. **Deep Dive**: Explore specific skills, locations, or time periods in detail\n",
    "3. **Custom Analysis**: Add your own visualizations and insights\n",
    "4. **Export**: Save figures for reports using `plt.savefig()`\n",
    "\n",
    "For more information, see the project README."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}